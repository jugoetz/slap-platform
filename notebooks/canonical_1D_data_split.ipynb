{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad91570",
   "metadata": {},
   "source": [
    "## 1D data split aldehydes\n",
    "\n",
    "(adapted from canonical_data_split.ipynb)\n",
    "We want a set of splits following this recipe:\n",
    "\n",
    "- First take away the last 96 records, which are meant as an external validation set (this is the last plate ice-12-103)\n",
    "- Of all remaining data, take away a 1D test set (on aldehydes). We use a 10fold GroupShuffleSplit here, with 10% test data. Note that because we are using group splits with uneven groups, these values will not be exact.\n",
    "- Of remaining data A, take away 1D validation set (10% of A, also on aldehydes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6026db0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:35.645502Z",
     "end_time": "2023-04-11T17:51:35.661495Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from src.data import SLAPData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc19918e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:35.652861Z",
     "end_time": "2023-04-11T17:51:38.156117Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "data_path = os.path.abspath(\"../data/Data S3.csv\")\n",
    "\n",
    "data = SLAPData(data_path)\n",
    "\n",
    "data.load_data_from_file()\n",
    "data.split_reaction_smiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4334e311",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:38.005443Z",
     "end_time": "2023-04-11T17:51:38.156382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 47]\n",
      " [ 7  0]\n",
      " [ 7 28]\n",
      " ...\n",
      " [34 10]\n",
      " [34 35]\n",
      " [34 11]]\n"
     ]
    }
   ],
   "source": [
    "print(data.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff3e921",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:38.008510Z",
     "end_time": "2023-04-11T17:51:38.156474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "859"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aede08d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:38.011661Z",
     "end_time": "2023-04-11T17:51:38.156515Z"
    }
   },
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=10, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d870e818",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:38.012999Z",
     "end_time": "2023-04-11T17:51:38.156624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for fold 0:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 575 \t|\t 55%\n",
      "Val_1D: \t 53 \t|\t 26%\n",
      "Test_1D: \t 135 \t|\t 47%\n",
      "Statistics for fold 1:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 601 \t|\t 54%\n",
      "Val_1D: \t 104 \t|\t 36%\n",
      "Test_1D: \t 58 \t|\t 50%\n",
      "Statistics for fold 2:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 579 \t|\t 52%\n",
      "Val_1D: \t 96 \t|\t 47%\n",
      "Test_1D: \t 88 \t|\t 56%\n",
      "Statistics for fold 3:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 588 \t|\t 53%\n",
      "Val_1D: \t 96 \t|\t 34%\n",
      "Test_1D: \t 79 \t|\t 58%\n",
      "Statistics for fold 4:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 577 \t|\t 53%\n",
      "Val_1D: \t 104 \t|\t 36%\n",
      "Test_1D: \t 82 \t|\t 61%\n",
      "Statistics for fold 5:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 601 \t|\t 58%\n",
      "Val_1D: \t 104 \t|\t 33%\n",
      "Test_1D: \t 58 \t|\t 17%\n",
      "Statistics for fold 6:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 628 \t|\t 52%\n",
      "Val_1D: \t 79 \t|\t 41%\n",
      "Test_1D: \t 56 \t|\t 59%\n",
      "Statistics for fold 7:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 612 \t|\t 53%\n",
      "Val_1D: \t 71 \t|\t 44%\n",
      "Test_1D: \t 80 \t|\t 50%\n",
      "Statistics for fold 8:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 608 \t|\t 51%\n",
      "Val_1D: \t 66 \t|\t 50%\n",
      "Test_1D: \t 89 \t|\t 53%\n",
      "Statistics for fold 9:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 588 \t|\t 48%\n",
      "Val_1D: \t 79 \t|\t 53%\n",
      "Test_1D: \t 96 \t|\t 71%\n",
      "\n",
      "Summary statistics:\n",
      "Split sizes: 78% train, 11% val, 11% test\n",
      "Class balance (positive class ratio): 53% train, 40% val, 53% test\n"
     ]
    }
   ],
   "source": [
    "# we use only the first 763 records, as the validation plate starts after that\n",
    "# (can be checked in generate_ml_datasets.ipynb).\n",
    "# Note that this is only applicable to the LCMS data set, not the isolated yields, which have less entries\n",
    "\n",
    "train_counter, val_counter, test_counter = 0, 0, 0\n",
    "train_pos_class, val_pos_class, test_pos_class = 0, 0, 0\n",
    "\n",
    "for i, (data_subset_A, test_1D) in enumerate(splitter.split(data.all_X[:763], groups=data.groups[:763, 1])):\n",
    "    \n",
    "    # we take a (1D) validation set. Rest is training set\n",
    "    inner_splitter = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=123)\n",
    "    train_idx, val_1D_idx = next(inner_splitter.split(data_subset_A, groups=data.groups[data_subset_A, 1]))\n",
    "    train = data_subset_A[train_idx]    #Â it may be slightly confusing that we index a list of indices here, \n",
    "    val_1D = data_subset_A[val_1D_idx]  # but it is necessary, as the splitter returns indices for data_subset_A.\n",
    "    \n",
    "    # update counters\n",
    "    train_counter += len(train)\n",
    "    val_counter += len(val_1D)\n",
    "    test_counter += len(test_1D)\n",
    "    train_pos_class += np.sum(data.all_y[train])\n",
    "    val_pos_class += np.sum(data.all_y[val_1D])\n",
    "    test_pos_class += np.sum(data.all_y[test_1D])\n",
    "    \n",
    "    print(f\"Statistics for fold {i}:\")\n",
    "    print(f\"ID \\t\\t num \\t|\\t %positive\")\n",
    "    print(f\"Train: \\t\\t {len(train)} \\t|\\t {np.mean(data.all_y[train]):.0%}\")\n",
    "    print(f\"Val_1D: \\t {len(val_1D)} \\t|\\t {np.mean(data.all_y[val_1D]):.0%}\")\n",
    "    print(f\"Test_1D: \\t {len(test_1D)} \\t|\\t {np.mean(data.all_y[test_1D]):.0%}\")\n",
    "    assert np.intersect1d(val_1D, test_1D).size == 0\n",
    "    assert np.intersect1d(train, test_1D).size == 0\n",
    "    assert np.intersect1d(train, val_1D).size == 0\n",
    "    \n",
    "    # save the indices\n",
    "    save = False\n",
    "    if save:\n",
    "        save_path = pathlib.Path(\"../data/dataset_splits/LCMS_split_763records_1Dsplit_aldehydes_10fold_v2\")\n",
    "        save_path.mkdir(parents=True, exist_ok=True)\n",
    "        pd.DataFrame(train).to_csv(save_path / f\"fold{i}_train.csv\", index=False, header=None)\n",
    "        pd.DataFrame(val_1D).to_csv(save_path / f\"fold{i}_val.csv\", index=False, header=None)\n",
    "        pd.DataFrame(test_1D).to_csv(save_path / f\"fold{i}_test_1D.csv\", index=False, header=None)\n",
    "        \n",
    "# summary statistics\n",
    "n = train_counter + val_counter + test_counter\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(f\"Split sizes: {train_counter/n:.0%} train, {val_counter/n:.0%} val, {test_counter/n:.0%} test\")\n",
    "print(f\"Class balance (positive class ratio): {train_pos_class/train_counter:.0%} train, {val_pos_class/val_counter:.0%} val, {test_pos_class/test_counter:.0%} test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcade5c3",
   "metadata": {},
   "source": [
    "## For SLAP reagents\n",
    "Same thing, but split on SLAP reagents, not aldehydes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23f0ab16",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:38.035236Z",
     "end_time": "2023-04-11T17:51:38.156654Z"
    }
   },
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=10, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4747ef1a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T17:51:38.041719Z",
     "end_time": "2023-04-11T17:51:38.156826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for fold 0:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 609 \t|\t 52%\n",
      "Val: \t\t 72 \t|\t 40%\n",
      "Test_1D: \t 82 \t|\t 60%\n",
      "Statistics for fold 1:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 602 \t|\t 51%\n",
      "Val: \t\t 72 \t|\t 60%\n",
      "Test_1D: \t 89 \t|\t 49%\n",
      "Statistics for fold 2:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 602 \t|\t 49%\n",
      "Val: \t\t 72 \t|\t 56%\n",
      "Test_1D: \t 89 \t|\t 63%\n",
      "Statistics for fold 3:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 619 \t|\t 52%\n",
      "Val: \t\t 72 \t|\t 51%\n",
      "Test_1D: \t 72 \t|\t 46%\n",
      "Statistics for fold 4:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 575 \t|\t 47%\n",
      "Val: \t\t 82 \t|\t 55%\n",
      "Test_1D: \t 106 \t|\t 72%\n",
      "Statistics for fold 5:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 619 \t|\t 52%\n",
      "Val: \t\t 72 \t|\t 44%\n",
      "Test_1D: \t 72 \t|\t 54%\n",
      "Statistics for fold 6:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 619 \t|\t 54%\n",
      "Val: \t\t 72 \t|\t 50%\n",
      "Test_1D: \t 72 \t|\t 29%\n",
      "Statistics for fold 7:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 619 \t|\t 52%\n",
      "Val: \t\t 72 \t|\t 49%\n",
      "Test_1D: \t 72 \t|\t 49%\n",
      "Statistics for fold 8:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 609 \t|\t 52%\n",
      "Val: \t\t 72 \t|\t 61%\n",
      "Test_1D: \t 82 \t|\t 37%\n",
      "Statistics for fold 9:\n",
      "ID \t\t num \t|\t %positive\n",
      "Train: \t\t 599 \t|\t 50%\n",
      "Val: \t\t 82 \t|\t 51%\n",
      "Test_1D: \t 82 \t|\t 62%\n",
      "\n",
      "Summary statistics:\n",
      "Split sizes: 80% train, 10% val, 11% test\n",
      "Class balance (positive class ratio): 51% train, 52% val, 53% test\n"
     ]
    }
   ],
   "source": [
    "# we use only the first 763 records, as the validation plate starts after that\n",
    "# (can be checked in generate_ml_datasets.ipynb).\n",
    "# Note that this is only applicable to the LCMS data set, not the isolated yields, which have less entries\n",
    "\n",
    "train_counter, val_counter, test_counter = 0, 0, 0\n",
    "train_pos_class, val_pos_class, test_pos_class = 0, 0, 0\n",
    "\n",
    "for i, (data_subset_A, test_1D) in enumerate(splitter.split(data.all_X[:763], groups=data.groups[:763, 0])):\n",
    "    \n",
    "    # we take a (1D) validation set. Rest is training set\n",
    "    inner_splitter = GroupShuffleSplit(n_splits=1, test_size=0.12, random_state=123)\n",
    "    train_idx, val_1D_idx = next(inner_splitter.split(data_subset_A, groups=data.groups[data_subset_A, 0]))\n",
    "    train = data_subset_A[train_idx]\n",
    "    val_1D = data_subset_A[val_1D_idx]\n",
    "    \n",
    "    # update counters\n",
    "    train_counter += len(train)\n",
    "    val_counter += len(val_1D)\n",
    "    test_counter += len(test_1D)\n",
    "    train_pos_class += np.sum(data.all_y[train])\n",
    "    val_pos_class += np.sum(data.all_y[val_1D])\n",
    "    test_pos_class += np.sum(data.all_y[test_1D])\n",
    "    \n",
    "    print(f\"Statistics for fold {i}:\")\n",
    "    print(f\"ID \\t\\t num \\t|\\t %positive\")\n",
    "    print(f\"Train: \\t\\t {len(train)} \\t|\\t {np.mean(data.all_y[train]):.0%}\")\n",
    "    print(f\"Val: \\t\\t {len(val_1D)} \\t|\\t {np.mean(data.all_y[val_1D]):.0%}\")\n",
    "    print(f\"Test_1D: \\t {len(test_1D)} \\t|\\t {np.mean(data.all_y[test_1D]):.0%}\")\n",
    "    assert np.intersect1d(val_1D, test_1D).size == 0\n",
    "    assert np.intersect1d(train, test_1D).size == 0\n",
    "    assert np.intersect1d(train, val_1D).size == 0\n",
    "    \n",
    "    # save the indices\n",
    "    save = False\n",
    "    if save:\n",
    "        save_path = pathlib.Path(\"../data/dataset_splits/LCMS_split_763records_1Dsplit_SLAP_10fold_v2\")\n",
    "        save_path.mkdir(parents=True, exist_ok=True)\n",
    "        pd.DataFrame(train).to_csv(save_path / f\"fold{i}_train.csv\", index=False, header=None)\n",
    "        pd.DataFrame(val_1D).to_csv(save_path / f\"fold{i}_val.csv\", index=False, header=None)\n",
    "        pd.DataFrame(test_1D).to_csv(save_path / f\"fold{i}_test_1D.csv\", index=False, header=None)\n",
    "\n",
    "# summary statistics\n",
    "n = train_counter + val_counter + test_counter\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(f\"Split sizes: {train_counter/n:.0%} train, {val_counter/n:.0%} val, {test_counter/n:.0%} test\")\n",
    "print(f\"Class balance (positive class ratio): {train_pos_class/train_counter:.0%} train, {val_pos_class/val_counter:.0%} val, {test_pos_class/test_counter:.0%} test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
